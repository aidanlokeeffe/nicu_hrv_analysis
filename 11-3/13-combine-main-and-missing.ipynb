{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import wfdb\n",
    "from wfdb import processing\n",
    "\n",
    "from gc import collect as collect_garbage\n",
    "from psutil import virtual_memory\n",
    "from os import scandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1a processed\n",
      "File 1b processed\n",
      "File 1c processed\n",
      "File 1d processed\n",
      "File 1e processed\n",
      "File 2a processed\n",
      "File 2b processed\n",
      "File 2c processed\n",
      "File 2d processed\n",
      "File 2e processed\n",
      "File 3a processed\n",
      "File 3b processed\n",
      "File 3c processed\n",
      "File 3d processed\n",
      "File 3e processed\n",
      "File 4a processed\n",
      "File 4b processed\n",
      "File 4c processed\n",
      "File 4d processed\n",
      "File 4e processed\n",
      "File 5a processed\n",
      "File 5b processed\n",
      "File 5c processed\n",
      "File 5d processed\n",
      "File 5e processed\n",
      "File 6a processed\n",
      "File 6b processed\n",
      "File 6c processed\n",
      "File 6d processed\n",
      "File 6e processed\n",
      "File 7a processed\n",
      "File 7b processed\n",
      "File 7c processed\n",
      "File 7d processed\n",
      "File 7e processed\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    for part in [\"a\", \"b\", \"c\", \"d\", \"e\"]:\n",
    "        bulk_signal = pd.read_csv(\"try_again/rpeaks_\" + str(i) + part + \".csv\")\n",
    "        missing_chunk = pd.read_csv(\"final_chunks/missing_rpeaks_\" + str(i) + part + \".csv\")\n",
    "        cutoff = max(bulk_signal[\"time\"])\n",
    "        filt = (missing_chunk[\"time\"] > cutoff)\n",
    "        missing_chunk = missing_chunk.loc[filt]\n",
    "        bulk_signal.append(missing_chunk).set_index(\"Unnamed: 0\").to_csv(\"completed_rpeaks/test_rpeaks_\" + str(i) + part + \".csv\")\n",
    "\n",
    "        del bulk_signal\n",
    "        del missing_chunk\n",
    "        del cutoff\n",
    "        del filt\n",
    "        collect_garbage()\n",
    "        print(\"File \" + str(i) + part + \" processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess now we can compute the RR intervals. We'll store them as differences, and put the starting time in the column in case that's important\n",
    "# We should also store the RR intervals if we throw out the troughs\n",
    "\n",
    "# But for now, let's just look at the unprocessed signals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b66384013171cdfccbfda8d4f96d2b3b6a10bf536bc42f61d1fe50046d47db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
