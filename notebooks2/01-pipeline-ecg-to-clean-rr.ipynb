{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "\n",
    "from gc import collect as collect_garbage\n",
    "from psutil import virtual_memory\n",
    "from os import scandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = \"../../Deidentified-Raw-Waveforms/\"\n",
    "folder = \"C:/Users/aidan/Box/Deidentified-Raw-Waveforms/\"\n",
    "coldict = {\n",
    "    \"raw_waves_data_1a.csv\": [\"time\", \"257\"], \"raw_waves_data_1b.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_1c.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_1d.csv\": [\"time\", \"257\", \"258\", \"317\"], \n",
    "    \"raw_waves_data_1e.csv\": [\"time\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_2a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_2b.csv\": [\"time\", \"258\"], \"raw_waves_data_2c.csv\": [\"time\", \"257\"], \"raw_waves_data_2d.csv\": [\"time\", \"257\", \"258\"], \n",
    "    \"raw_waves_data_2e.csv\": [\"time\", \"257\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_3a.csv\": [\"time\", \"258\"], \"raw_waves_data_3b.csv\": [\"time\", \"258\"], \"raw_waves_data_3c.csv\": [\"time\", \"258\"], \"raw_waves_data_3d.csv\": [\"time\", \"258\"], \n",
    "    \"raw_waves_data_3e.csv\": [\"time\", \"257\", \"258\", \"317\"],\n",
    "\n",
    "    \"raw_waves_data_4a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_4b.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_4c.csv\": [\"time\", \"257\"], \"raw_waves_data_4d.csv\": [\"time\", \"257\", \"258\"], \n",
    "    \"raw_waves_data_4e.csv\": [\"time\", \"257\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_5a.csv\": [\"time\", \"258\"], \"raw_waves_data_5b.csv\": [\"time\", \"258\"], \"raw_waves_data_5c.csv\": [\"time\", \"258\"], \"raw_waves_data_5d.csv\": [\"time\", \"258\", \"317\"],\n",
    "    \"raw_waves_data_5e.csv\": [\"time\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_6a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_6b.csv\": [\"time\", \"258\"], \"raw_waves_data_6c.csv\": [\"time\", \"258\"], \"raw_waves_data_6d.csv\": [\"time\", \"258\"], \"raw_waves_data_6e.csv\": [\"time\", \"258\"],\n",
    "    \n",
    "    \"raw_waves_data_7a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_7b.csv\": [\"time\", \"258\"], \"raw_waves_data_7c.csv\": [\"time\", \"258\"], \"raw_waves_data_7d.csv\": [\"time\", \"257\", \"258\", \"317\"], \n",
    "    \"raw_waves_data_7e.csv\": [\"time\", \"258\"]\n",
    "}\n",
    "\n",
    "namedict = {\n",
    "    \"raw_waves_data_1a.csv\": \"1a\", \"raw_waves_data_1b.csv\": \"1b\", \"raw_waves_data_1c.csv\": \"1c\", \"raw_waves_data_1d.csv\": \"1d\", \"raw_waves_data_1e.csv\": \"1e\",\n",
    "    \"raw_waves_data_2a.csv\": \"2a\", \"raw_waves_data_2b.csv\": \"2b\", \"raw_waves_data_2c.csv\": \"2c\", \"raw_waves_data_2d.csv\": \"2d\", \"raw_waves_data_2e.csv\": \"2e\",\n",
    "    \"raw_waves_data_3a.csv\": \"3a\", \"raw_waves_data_3b.csv\": \"3b\", \"raw_waves_data_3c.csv\": \"3c\", \"raw_waves_data_3d.csv\": \"3d\", \"raw_waves_data_3e.csv\": \"3e\",\n",
    "    \"raw_waves_data_4a.csv\": \"4a\", \"raw_waves_data_4b.csv\": \"4b\", \"raw_waves_data_4c.csv\": \"4c\", \"raw_waves_data_4d.csv\": \"4d\", \"raw_waves_data_4e.csv\": \"4e\",\n",
    "    \"raw_waves_data_5a.csv\": \"5a\", \"raw_waves_data_5b.csv\": \"5b\", \"raw_waves_data_5c.csv\": \"5c\", \"raw_waves_data_5d.csv\": \"5d\", \"raw_waves_data_5e.csv\": \"5e\",\n",
    "    \"raw_waves_data_6a.csv\": \"6a\", \"raw_waves_data_6b.csv\": \"6b\", \"raw_waves_data_6c.csv\": \"6c\", \"raw_waves_data_6d.csv\": \"6d\", \"raw_waves_data_6e.csv\": \"6e\",\n",
    "    \"raw_waves_data_7a.csv\": \"7a\", \"raw_waves_data_7b.csv\": \"7b\", \"raw_waves_data_7c.csv\": \"7c\", \"raw_waves_data_7d.csv\": \"7d\", \"raw_waves_data_7e.csv\": \"7e\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=12655771648, available=5637320704, percent=55.5, used=7018450944, free=5637320704)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_garbage()\n",
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [folder + file.name for file in scandir(folder) if \".csv\" in file.name]\n",
    "\n",
    "# We need to replace some of the files with the shifted files produced in notebook 06\n",
    "all_files[5] =  folder+'06-shifted-2-and-3/raw_waves_data_2a.csv'\n",
    "all_files[6] =  folder+'06-shifted-2-and-3/raw_waves_data_2b.csv'\n",
    "all_files[10] =  folder+'06-shifted-2-and-3/raw_waves_data_3a.csv'\n",
    "all_files[11] =  folder+'06-shifted-2-and-3/raw_waves_data_3b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now with raw_waves_data_1a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6585 chunks\n",
      "0.0% percent done\n",
      "15.190000000000001% percent done\n",
      "30.37% percent done\n",
      "45.56% percent done\n",
      "60.74% percent done\n",
      "75.92999999999999% percent done\n",
      "91.12% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "58.6 memory usage\n",
      "Starting now with raw_waves_data_1b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6524 chunks\n",
      "0.0% percent done\n",
      "15.329999999999998% percent done\n",
      "30.659999999999997% percent done\n",
      "45.98% percent done\n",
      "61.309999999999995% percent done\n",
      "76.64% percent done\n",
      "91.97% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "56.8 memory usage\n",
      "Starting now with raw_waves_data_1c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6480 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.86% percent done\n",
      "46.300000000000004% percent done\n",
      "61.73% percent done\n",
      "77.16% percent done\n",
      "92.58999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "56.8 memory usage\n",
      "Starting now with raw_waves_data_1d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6482 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.85% percent done\n",
      "46.28% percent done\n",
      "61.71% percent done\n",
      "77.14% percent done\n",
      "92.56% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "55.3 memory usage\n",
      "Starting now with raw_waves_data_1e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "56.5 memory usage\n",
      "Starting now with raw_waves_data_2a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6480 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.86% percent done\n",
      "46.300000000000004% percent done\n",
      "61.73% percent done\n",
      "77.16% percent done\n",
      "92.58999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "55.0 memory usage\n",
      "Starting now with raw_waves_data_2b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "54.5 memory usage\n",
      "Starting now with raw_waves_data_2c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6476 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.77% percent done\n",
      "77.21000000000001% percent done\n",
      "92.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "53.7 memory usage\n",
      "Starting now with raw_waves_data_2d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6441 chunks\n",
      "0.0% percent done\n",
      "15.53% percent done\n",
      "31.05% percent done\n",
      "46.58% percent done\n",
      "62.1% percent done\n",
      "77.63% percent done\n",
      "93.15% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.6 memory usage\n",
      "Starting now with raw_waves_data_2e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6453 chunks\n",
      "0.0% percent done\n",
      "15.5% percent done\n",
      "30.990000000000002% percent done\n",
      "46.489999999999995% percent done\n",
      "61.99% percent done\n",
      "77.48% percent done\n",
      "92.97999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "54.9 memory usage\n",
      "Starting now with raw_waves_data_3a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6431 chunks\n",
      "0.0% percent done\n",
      "15.55% percent done\n",
      "31.1% percent done\n",
      "46.650000000000006% percent done\n",
      "62.2% percent done\n",
      "77.75% percent done\n",
      "93.30000000000001% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "53.7 memory usage\n",
      "Starting now with raw_waves_data_3b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 1754 chunks\n",
      "0.0% percent done\n",
      "57.010000000000005% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "49.8 memory usage\n",
      "Starting now with raw_waves_data_3c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6405 chunks\n",
      "0.0% percent done\n",
      "15.61% percent done\n",
      "31.230000000000004% percent done\n",
      "46.839999999999996% percent done\n",
      "62.45% percent done\n",
      "78.06% percent done\n",
      "93.67999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.2 memory usage\n",
      "Starting now with raw_waves_data_3d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6404 chunks\n",
      "0.0% percent done\n",
      "15.620000000000001% percent done\n",
      "31.230000000000004% percent done\n",
      "46.85% percent done\n",
      "62.46000000000001% percent done\n",
      "78.08% percent done\n",
      "93.69% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.5 memory usage\n",
      "Starting now with raw_waves_data_3e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6398 chunks\n",
      "0.0% percent done\n",
      "15.629999999999999% percent done\n",
      "31.259999999999998% percent done\n",
      "46.89% percent done\n",
      "62.519999999999996% percent done\n",
      "78.14999999999999% percent done\n",
      "93.78% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.6 memory usage\n",
      "Starting now with raw_waves_data_4a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "50.9 memory usage\n",
      "Starting now with raw_waves_data_4b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "50.8 memory usage\n",
      "Starting now with raw_waves_data_4c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6476 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.77% percent done\n",
      "77.21000000000001% percent done\n",
      "92.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.2 memory usage\n",
      "Starting now with raw_waves_data_4d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6441 chunks\n",
      "0.0% percent done\n",
      "15.53% percent done\n",
      "31.05% percent done\n",
      "46.58% percent done\n",
      "62.1% percent done\n",
      "77.63% percent done\n",
      "93.15% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.3 memory usage\n",
      "Starting now with raw_waves_data_4e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6453 chunks\n",
      "0.0% percent done\n",
      "15.5% percent done\n",
      "30.990000000000002% percent done\n",
      "46.489999999999995% percent done\n",
      "61.99% percent done\n",
      "77.48% percent done\n",
      "92.97999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.6 memory usage\n",
      "Starting now with raw_waves_data_5a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6433 chunks\n",
      "0.0% percent done\n",
      "15.540000000000001% percent done\n",
      "31.09% percent done\n",
      "46.63% percent done\n",
      "62.18% percent done\n",
      "77.72% percent done\n",
      "93.27% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.6 memory usage\n",
      "Starting now with raw_waves_data_5b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6483 chunks\n",
      "0.0% percent done\n",
      "15.42% percent done\n",
      "30.85% percent done\n",
      "46.27% percent done\n",
      "61.7% percent done\n",
      "77.12% percent done\n",
      "92.55% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.2 memory usage\n",
      "Starting now with raw_waves_data_5c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.7 memory usage\n",
      "Starting now with raw_waves_data_5d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "53.4 memory usage\n",
      "Starting now with raw_waves_data_5e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6482 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.85% percent done\n",
      "46.28% percent done\n",
      "61.71% percent done\n",
      "77.14% percent done\n",
      "92.56% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.4 memory usage\n",
      "Starting now with raw_waves_data_6a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.4 memory usage\n",
      "Starting now with raw_waves_data_6b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "51.8 memory usage\n",
      "Starting now with raw_waves_data_6c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.4 memory usage\n",
      "Starting now with raw_waves_data_6d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "60.9 memory usage\n",
      "Starting now with raw_waves_data_6e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "53.5 memory usage\n",
      "Starting now with raw_waves_data_7a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.3 memory usage\n",
      "Starting now with raw_waves_data_7b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6475 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.89% percent done\n",
      "46.33% percent done\n",
      "61.78% percent done\n",
      "77.22% percent done\n",
      "92.66% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "55.2 memory usage\n",
      "Starting now with raw_waves_data_7c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "70.2 memory usage\n",
      "Starting now with raw_waves_data_7d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.6 memory usage\n",
      "Starting now with raw_waves_data_7e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6407 chunks\n",
      "0.0% percent done\n",
      "15.61% percent done\n",
      "31.22% percent done\n",
      "46.82% percent done\n",
      "62.43% percent done\n",
      "78.03999999999999% percent done\n",
      "93.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "52.5 memory usage\n"
     ]
    }
   ],
   "source": [
    "# This is the code that detects QRS complexes in the ECG\n",
    "for i in range(1,8):\n",
    "    files = [file for file in all_files if \"_\"+str(i) in file]\n",
    "\n",
    "    for file in files:\n",
    "        # Preliminaries\n",
    "        key = file.split(\"/\")[-1]\n",
    "        cols = coldict[key]\n",
    "        freq = 250\n",
    "        print(\"Starting now with \" + key)\n",
    "\n",
    "        # Read in the data\n",
    "        df = pd.read_csv(file, usecols=cols)\n",
    "        print(\"Data loaded in\")\n",
    "\n",
    "        # Complete the signal in the order of 257 (ECG1), then  258 (ECG2), and \n",
    "        # then 317 (EG3), then ffill for remaining missing values\n",
    "        signal = pd.Series(df[cols[1]])\n",
    "        i=2\n",
    "        while True:\n",
    "            try:\n",
    "                signal = signal.combine_first(df[cols[i]])\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                break\n",
    "        signal = signal.fillna(method=\"ffill\")\n",
    "        signal = pd.to_numeric(signal)\n",
    "        print(\"Signals combined and filled in\")\n",
    "\n",
    "        # Remove spikes and troughs by pinpointing values out of bounds and then \n",
    "        # erasing left and right of those pinpoints by delta indices\n",
    "        delta = 125\n",
    "        filt = (signal <= -10) | (signal >= 10)\n",
    "        filt.loc[~filt] = np.nan\n",
    "        filt.fillna(method=\"ffill\", limit=delta, inplace=True)\n",
    "        filt.fillna(method=\"bfill\", limit=delta, inplace=True)\n",
    "        filt.fillna(value=False, inplace=True)\n",
    "\n",
    "        signal.loc[filt] = np.nan\n",
    "        signal.fillna(method=\"ffill\", inplace=True)\n",
    "        print(\"Troughs and spikes removed\")\n",
    "\n",
    "        # Initialize the rpeak list\n",
    "        rpeaks = []\n",
    "\n",
    "        # Create a counter for breaking the signal into chunks\n",
    "        i=0\n",
    "        N = len(signal)\n",
    "        chunk = 10000\n",
    "        num_chunks = N//chunk + 1\n",
    "        print(\"Signal broken into \" + str(num_chunks) + \" chunks\")\n",
    "\n",
    "        # Find R peaks in all but the last chunk (that just tends to cause a problem)\n",
    "        while True:\n",
    "            try:\n",
    "                if i%1000 == 0:\n",
    "                    # I've found this choice of progress marker works for this chunk\n",
    "                    # size and signal length. If those values change, then this \n",
    "                    # condition will need to be modified too\n",
    "                    print( str(round(i/num_chunks,4)*100) + \"% percent done\" )\n",
    "\n",
    "                lo = i*chunk\n",
    "                hi = min( (i+1)*chunk, N)\n",
    "                xqrs = processing.XQRS(sig=signal[lo:hi], fs=freq)\n",
    "                xqrs.detect(verbose=False)\n",
    "\n",
    "                # xqrs recognized the chunk as starting from 0, so we have to shift \n",
    "                # the R peaks according to the left endpoint of the chunk\n",
    "                rpeaks += list( lo + xqrs.qrs_inds )\n",
    "\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                # This is the main way in which we'd expect to break this loop\n",
    "                break\n",
    "            except ValueError:\n",
    "                # More often than not, we get this case because the last chunk isn't \n",
    "                # long enough, hence the next block\n",
    "                break\n",
    "        print(\"R peaks outside of the last chunk located\")\n",
    "\n",
    "        # Delineate an ending chunk of like 20000 indices that gets the end of the\n",
    "        # signal, find R peaks\n",
    "        hi = len(signal)\n",
    "        lo = hi - 20000\n",
    "        xqrs = processing.XQRS(sig=signal[lo:hi], fs=freq)\n",
    "        xqrs.detect(verbose=False)\n",
    "\n",
    "        rpeaks += [ peak for peak in xqrs.qrs_inds if peak > max(rpeaks)]\n",
    "        print(\"Peaks in final chunk located\")\n",
    "\n",
    "        # Grab the time stamps, write them to a file\n",
    "        df.loc[rpeaks, \"time\"].to_csv(\"01-outputs/00-rpeaks/rpeaks_\" + namedict[key] + \".csv\", )\n",
    "        print(\"Output file written\")\n",
    "\n",
    "        # Delete all of the variables to save space\n",
    "        del df\n",
    "        del xqrs\n",
    "        del signal\n",
    "        del rpeaks\n",
    "        collect_garbage()\n",
    "\n",
    "        print(str(virtual_memory()[2]) + \" memory usage\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=12655771648, available=5862969344, percent=53.7, used=6792802304, free=5862969344)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now with infant 1\n",
      "Infant 1 R peaks all loaded in\n",
      "Uncleaned RR Intervals Written\n",
      "Intervals outside of [0.25, 5] filtered out\n",
      "0.0% Complete\n",
      "5.0% Complete\n",
      "10.0% Complete\n",
      "14.99% Complete\n",
      "19.98% Complete\n",
      "24.97% Complete\n",
      "29.959999999999997% Complete\n",
      "34.94% Complete\n",
      "39.93% Complete\n",
      "44.91% Complete\n",
      "49.88% Complete\n",
      "54.86% Complete\n",
      "59.830000000000005% Complete\n",
      "64.8% Complete\n",
      "69.76% Complete\n",
      "74.72999999999999% Complete\n",
      "79.67999999999999% Complete\n",
      "84.63000000000001% Complete\n",
      "89.59% Complete\n",
      "94.53% Complete\n",
      "99.47% Complete\n",
      "Multiple intervals all broken up\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15096/1138118735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# Now, we write the new dataframe to 5 different csvs so that they can be pushed to GitHub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0mfile_bounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"e\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "input_folder = \"01-outputs/00-rpeaks/\"\n",
    "output_folder = \"01-outputs/01-rr-intervals/\"\n",
    "for i in range(2,8):\n",
    "    print(\"Starting now with infant \" + str(i))\n",
    "\n",
    "    # Get the names of the rpeak files\n",
    "    rpeak_files = sorted([file.name for file in scandir(\"01-outputs/00-rpeaks/\") if str(i) in file.name])\n",
    "\n",
    "    # Concatenate all of these dataframes\n",
    "    df = pd.read_csv( input_folder + rpeak_files.pop(0) )\n",
    "    for file in rpeak_files:\n",
    "        df = df.append( pd.read_csv(input_folder + file) )\n",
    "        collect_garbage()\n",
    "    print(\"Infant \" + str(i) + \" R peaks all loaded in\")\n",
    "\n",
    "    # Clean up df, calculate the RR intervals\n",
    "    df.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df[\"interval\"] = df[\"time\"].diff()\n",
    "    print(\"Uncleaned RR Intervals Written\")\n",
    "\n",
    "    # Recalculate RR intervals while ignoring beats whose RR intervals are < 0.25 seconds\n",
    "    filt = df[\"interval\"] >= 0.25\n",
    "\n",
    "    new_df = pd.DataFrame.copy(df.loc[filt], deep=True)\n",
    "    new_df.reset_index(inplace=True, drop=True)\n",
    "    new_df[\"interval\"] = new_df[\"time\"].diff()\n",
    "\n",
    "    del df\n",
    "    collect_garbage()\n",
    "    df = pd.DataFrame.copy(new_df, deep=True)\n",
    "    del new_df\n",
    "    collect_garbage()\n",
    "\n",
    "    # Remove intervals of length greater than 5 seconds (arbitrary threshold)\n",
    "    # The resulting gaps will just be treated as missing data\n",
    "    filt = df[\"interval\"] <= 5\n",
    "    df = df.loc[filt]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    print(\"Intervals outside of [0.25, 5] filtered out\")\n",
    "\n",
    "    # Get rid of any remaining multiple intervals\n",
    "    df.set_index(df[\"time\"], inplace=True)\n",
    "    df.drop(\"time\", inplace=True, axis=1)\n",
    "\n",
    "    df_buffer = pd.DataFrame.copy(df, deep=True)\n",
    "\n",
    "    # THE FOLLOWING CODE IS EXTREMELY SLOW\n",
    "    # For a generator to iterate over the rows\n",
    "    rows = df_buffer.iterrows()\n",
    "    \n",
    "    # Get the initial values\n",
    "    prev_idx, prev_row = next(rows)\n",
    "    prev_ivl = prev_row[\"interval\"]\n",
    "\n",
    "    # A counter to see how many beats were imputed\n",
    "    imputed = 0\n",
    "    max_imputed = 0\n",
    "\n",
    "    # Counter for progress measurement\n",
    "    counter = 0\n",
    "    progress_chunk = len(df[\"interval\"])//20\n",
    "\n",
    "    for curr_idx, curr_row in rows:\n",
    "        if counter % progress_chunk == 0:\n",
    "            print( str(round(counter/len(df[\"interval\"]), 4)*100 ) + \"% Complete\" )\n",
    "        counter += 1\n",
    "\n",
    "        curr_ivl = curr_row[\"interval\"]\n",
    "\n",
    "        pieces = round(curr_ivl/prev_ivl)\n",
    "\n",
    "        if pieces >= 2: # Then it is likely that the current interval is a multiple interval\n",
    "            fill_value = curr_ivl / pieces\n",
    "\n",
    "            while fill_value < 0.25: # We have too many pieces and the fill value is too small\n",
    "                pieces -= 1\n",
    "                fill_value = curr_ivl/pieces\n",
    "                if pieces == 1:\n",
    "                    break\n",
    "            \n",
    "            if pieces == 1: # Then there's no point in carrying on with this iteration\n",
    "                prev_idx = curr_idx\n",
    "                prev_ivl = curr_ivl\n",
    "                continue\n",
    "\n",
    "            # Otherwise, we impute the RR intervals, modifying df and NOT df_buffer\n",
    "            imputed += pieces\n",
    "            max_imputed = max(max_imputed, pieces)\n",
    "\n",
    "            endpoints = [prev_idx + i*fill_value for i in range(1,pieces)] + [curr_idx]\n",
    "            for t in endpoints:\n",
    "                df.loc[t,\"interval\"] = fill_value\n",
    "            \n",
    "            # Now, we update the previous values ahead of the next iteration\n",
    "            prev_idx = curr_idx\n",
    "            prev_ivl = fill_value\n",
    "            continue\n",
    "\n",
    "        # If we didn't enter the pieces >= 2 case, then twe need to update the previous values in a different way\n",
    "        prev_idx = curr_idx\n",
    "        prev_ivl = curr_ivl\n",
    "\n",
    "    print(\"Multiple intervals all broken up\")\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    del df_buffer\n",
    "\n",
    "    # Now, we write the new dataframe to 5 different csvs so that they can be pushed to GitHub\n",
    "    N = len(df[\"interval\"])\n",
    "    file_bounds = [k*N//5 for k in range(0,6)]\n",
    "    parts = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    \n",
    "    for k in range(5):\n",
    "        df.iloc[file_bounds[k]:file_bounds[k+1]].to_csv(output_folder + \"rr_intervals_\"+str(i)+parts[k]+\".csv\")\n",
    "\n",
    "    print(\"Imputed:\", imputed)\n",
    "    print(\"Max Imputed:\", max_imputed)\n",
    "    del df\n",
    "    del rows\n",
    "    collect_garbage()\n",
    "    print(\"Cleaned RR intervals written to file, \"+str(virtual_memory()[2])+\"% memory usage\\n\")\n",
    "\n",
    "    break # This is to check that everything is good with infant 1 before spending tons of time on the others\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df[\"interval\"])\n",
    "file_bounds = [k*N//5 for k in range(0,6)]\n",
    "parts = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    \n",
    "for k in range(5):\n",
    "    df.iloc[file_bounds[k]:file_bounds[k+1]].to_csv(output_folder + \"rr_intervals_\"+str(i)+parts[k]+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b66384013171cdfccbfda8d4f96d2b3b6a10bf536bc42f61d1fe50046d47db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
