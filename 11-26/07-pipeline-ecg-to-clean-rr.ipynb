{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "\n",
    "from gc import collect as collect_garbage\n",
    "from psutil import virtual_memory\n",
    "from os import scandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../../Deidentified-Raw-Waveforms/\"\n",
    "coldict = {\n",
    "    \"raw_waves_data_1a.csv\": [\"time\", \"257\"], \"raw_waves_data_1b.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_1c.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_1d.csv\": [\"time\", \"257\", \"258\", \"317\"], \n",
    "    \"raw_waves_data_1e.csv\": [\"time\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_2a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_2b.csv\": [\"time\", \"258\"], \"raw_waves_data_2c.csv\": [\"time\", \"257\"], \"raw_waves_data_2d.csv\": [\"time\", \"257\", \"258\"], \n",
    "    \"raw_waves_data_2e.csv\": [\"time\", \"257\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_3a.csv\": [\"time\", \"258\"], \"raw_waves_data_3b.csv\": [\"time\", \"258\"], \"raw_waves_data_3c.csv\": [\"time\", \"258\"], \"raw_waves_data_3d.csv\": [\"time\", \"258\"], \n",
    "    \"raw_waves_data_3e.csv\": [\"time\", \"257\", \"258\", \"317\"],\n",
    "\n",
    "    \"raw_waves_data_4a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_4b.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_4c.csv\": [\"time\", \"257\"], \"raw_waves_data_4d.csv\": [\"time\", \"257\", \"258\"], \n",
    "    \"raw_waves_data_4e.csv\": [\"time\", \"257\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_5a.csv\": [\"time\", \"258\"], \"raw_waves_data_5b.csv\": [\"time\", \"258\"], \"raw_waves_data_5c.csv\": [\"time\", \"258\"], \"raw_waves_data_5d.csv\": [\"time\", \"258\", \"317\"],\n",
    "    \"raw_waves_data_5e.csv\": [\"time\", \"258\"],\n",
    "\n",
    "    \"raw_waves_data_6a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_6b.csv\": [\"time\", \"258\"], \"raw_waves_data_6c.csv\": [\"time\", \"258\"], \"raw_waves_data_6d.csv\": [\"time\", \"258\"], \"raw_waves_data_6e.csv\": [\"time\", \"258\"],\n",
    "    \n",
    "    \"raw_waves_data_7a.csv\": [\"time\", \"257\", \"258\"], \"raw_waves_data_7b.csv\": [\"time\", \"258\"], \"raw_waves_data_7c.csv\": [\"time\", \"258\"], \"raw_waves_data_7d.csv\": [\"time\", \"257\", \"258\", \"317\"], \n",
    "    \"raw_waves_data_7e.csv\": [\"time\", \"258\"]\n",
    "}\n",
    "\n",
    "namedict = {\n",
    "    \"raw_waves_data_1a.csv\": \"1a\", \"raw_waves_data_1b.csv\": \"1b\", \"raw_waves_data_1c.csv\": \"1c\", \"raw_waves_data_1d.csv\": \"1d\", \"raw_waves_data_1e.csv\": \"1e\",\n",
    "    \"raw_waves_data_2a.csv\": \"2a\", \"raw_waves_data_2b.csv\": \"2b\", \"raw_waves_data_2c.csv\": \"2c\", \"raw_waves_data_2d.csv\": \"2d\", \"raw_waves_data_2e.csv\": \"2e\",\n",
    "    \"raw_waves_data_3a.csv\": \"3a\", \"raw_waves_data_3b.csv\": \"3b\", \"raw_waves_data_3c.csv\": \"3c\", \"raw_waves_data_3d.csv\": \"3d\", \"raw_waves_data_3e.csv\": \"3e\",\n",
    "    \"raw_waves_data_4a.csv\": \"4a\", \"raw_waves_data_4b.csv\": \"4b\", \"raw_waves_data_4c.csv\": \"4c\", \"raw_waves_data_4d.csv\": \"4d\", \"raw_waves_data_4e.csv\": \"4e\",\n",
    "    \"raw_waves_data_5a.csv\": \"5a\", \"raw_waves_data_5b.csv\": \"5b\", \"raw_waves_data_5c.csv\": \"5c\", \"raw_waves_data_5d.csv\": \"5d\", \"raw_waves_data_5e.csv\": \"5e\",\n",
    "    \"raw_waves_data_6a.csv\": \"6a\", \"raw_waves_data_6b.csv\": \"6b\", \"raw_waves_data_6c.csv\": \"6c\", \"raw_waves_data_6d.csv\": \"6d\", \"raw_waves_data_6e.csv\": \"6e\",\n",
    "    \"raw_waves_data_7a.csv\": \"7a\", \"raw_waves_data_7b.csv\": \"7b\", \"raw_waves_data_7c.csv\": \"7c\", \"raw_waves_data_7d.csv\": \"7d\", \"raw_waves_data_7e.csv\": \"7e\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=12655771648, available=5801984000, percent=54.2, used=6853787648, free=5801984000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_garbage()\n",
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [folder + file.name for file in scandir(folder) if \".csv\" in file.name]\n",
    "\n",
    "# We need to replace some of the files with the shifted files produced in notebook 06\n",
    "all_files[5] =  '../../Deidentified-Raw-Waveforms/06-shifted-2-and-3/raw_waves_data_2a.csv'\n",
    "all_files[6] =  '../../Deidentified-Raw-Waveforms/06-shifted-2-and-3/raw_waves_data_2b.csv'\n",
    "all_files[10] =  '../../Deidentified-Raw-Waveforms/06-shifted-2-and-3/raw_waves_data_3a.csv'\n",
    "all_files[11] =  '../../Deidentified-Raw-Waveforms/06-shifted-2-and-3/raw_waves_data_3b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now with raw_waves_data_2a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6480 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.86% percent done\n",
      "46.300000000000004% percent done\n",
      "61.73% percent done\n",
      "77.16% percent done\n",
      "92.58999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "49.2 memory usage\n",
      "Starting now with raw_waves_data_2b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "48.6 memory usage\n",
      "Starting now with raw_waves_data_2c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6476 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.77% percent done\n",
      "77.21000000000001% percent done\n",
      "92.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "48.0 memory usage\n",
      "Starting now with raw_waves_data_2d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6441 chunks\n",
      "0.0% percent done\n",
      "15.53% percent done\n",
      "31.05% percent done\n",
      "46.58% percent done\n",
      "62.1% percent done\n",
      "77.63% percent done\n",
      "93.15% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.1 memory usage\n",
      "Starting now with raw_waves_data_2e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6453 chunks\n",
      "0.0% percent done\n",
      "15.5% percent done\n",
      "30.990000000000002% percent done\n",
      "46.489999999999995% percent done\n",
      "61.99% percent done\n",
      "77.48% percent done\n",
      "92.97999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "46.8 memory usage\n",
      "Starting now with raw_waves_data_3a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6431 chunks\n",
      "0.0% percent done\n",
      "15.55% percent done\n",
      "31.1% percent done\n",
      "46.650000000000006% percent done\n",
      "62.2% percent done\n",
      "77.75% percent done\n",
      "93.30000000000001% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.3 memory usage\n",
      "Starting now with raw_waves_data_3b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 1754 chunks\n",
      "0.0% percent done\n",
      "57.010000000000005% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "43.5 memory usage\n",
      "Starting now with raw_waves_data_3c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6405 chunks\n",
      "0.0% percent done\n",
      "15.61% percent done\n",
      "31.230000000000004% percent done\n",
      "46.839999999999996% percent done\n",
      "62.45% percent done\n",
      "78.06% percent done\n",
      "93.67999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.7 memory usage\n",
      "Starting now with raw_waves_data_3d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6404 chunks\n",
      "0.0% percent done\n",
      "15.620000000000001% percent done\n",
      "31.230000000000004% percent done\n",
      "46.85% percent done\n",
      "62.46000000000001% percent done\n",
      "78.08% percent done\n",
      "93.69% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "46.2 memory usage\n",
      "Starting now with raw_waves_data_3e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6398 chunks\n",
      "0.0% percent done\n",
      "15.629999999999999% percent done\n",
      "31.259999999999998% percent done\n",
      "46.89% percent done\n",
      "62.519999999999996% percent done\n",
      "78.14999999999999% percent done\n",
      "93.78% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.9 memory usage\n",
      "Starting now with raw_waves_data_4a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.8 memory usage\n",
      "Starting now with raw_waves_data_4b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.1 memory usage\n",
      "Starting now with raw_waves_data_4c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6476 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.77% percent done\n",
      "77.21000000000001% percent done\n",
      "92.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.9 memory usage\n",
      "Starting now with raw_waves_data_4d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6441 chunks\n",
      "0.0% percent done\n",
      "15.53% percent done\n",
      "31.05% percent done\n",
      "46.58% percent done\n",
      "62.1% percent done\n",
      "77.63% percent done\n",
      "93.15% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.6 memory usage\n",
      "Starting now with raw_waves_data_4e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6453 chunks\n",
      "0.0% percent done\n",
      "15.5% percent done\n",
      "30.990000000000002% percent done\n",
      "46.489999999999995% percent done\n",
      "61.99% percent done\n",
      "77.48% percent done\n",
      "92.97999999999999% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "46.2 memory usage\n",
      "Starting now with raw_waves_data_5a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6433 chunks\n",
      "0.0% percent done\n",
      "15.540000000000001% percent done\n",
      "31.09% percent done\n",
      "46.63% percent done\n",
      "62.18% percent done\n",
      "77.72% percent done\n",
      "93.27% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "46.8 memory usage\n",
      "Starting now with raw_waves_data_5b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6483 chunks\n",
      "0.0% percent done\n",
      "15.42% percent done\n",
      "30.85% percent done\n",
      "46.27% percent done\n",
      "61.7% percent done\n",
      "77.12% percent done\n",
      "92.55% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "46.0 memory usage\n",
      "Starting now with raw_waves_data_5c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "45.5 memory usage\n",
      "Starting now with raw_waves_data_5d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "49.1 memory usage\n",
      "Starting now with raw_waves_data_5e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6482 chunks\n",
      "0.0% percent done\n",
      "15.43% percent done\n",
      "30.85% percent done\n",
      "46.28% percent done\n",
      "61.71% percent done\n",
      "77.14% percent done\n",
      "92.56% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.4 memory usage\n",
      "Starting now with raw_waves_data_6a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.4 memory usage\n",
      "Starting now with raw_waves_data_6b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "48.0 memory usage\n",
      "Starting now with raw_waves_data_6c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.0 memory usage\n",
      "Starting now with raw_waves_data_6d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "48.2 memory usage\n",
      "Starting now with raw_waves_data_6e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.2 memory usage\n",
      "Starting now with raw_waves_data_7a.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.1 memory usage\n",
      "Starting now with raw_waves_data_7b.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6475 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.89% percent done\n",
      "46.33% percent done\n",
      "61.78% percent done\n",
      "77.22% percent done\n",
      "92.66% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "48.1 memory usage\n",
      "Starting now with raw_waves_data_7c.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "54.4 memory usage\n",
      "Starting now with raw_waves_data_7d.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6477 chunks\n",
      "0.0% percent done\n",
      "15.440000000000001% percent done\n",
      "30.880000000000003% percent done\n",
      "46.32% percent done\n",
      "61.760000000000005% percent done\n",
      "77.2% percent done\n",
      "92.64% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.9 memory usage\n",
      "Starting now with raw_waves_data_7e.csv\n",
      "Data loaded in\n",
      "Signals combined and filled in\n",
      "Troughs and spikes removed\n",
      "Signal broken into 6407 chunks\n",
      "0.0% percent done\n",
      "15.61% percent done\n",
      "31.22% percent done\n",
      "46.82% percent done\n",
      "62.43% percent done\n",
      "78.03999999999999% percent done\n",
      "93.65% percent done\n",
      "R peaks outside of the last chunk located\n",
      "Peaks in final chunk located\n",
      "Output file written\n",
      "47.9 memory usage\n"
     ]
    }
   ],
   "source": [
    "# This is the code that detects QRS complexes in the ECG. We're skipping infant\n",
    "# 1 because they were treated as the pipeline was developed\n",
    "for i in range(2,8):\n",
    "    files = [file for file in all_files if \"_\"+str(i) in file]\n",
    "\n",
    "    for file in files:\n",
    "        # Preliminaries\n",
    "        key = file.split(\"/\")[-1]\n",
    "        cols = coldict[key]\n",
    "        freq = 250\n",
    "        print(\"Starting now with \" + key)\n",
    "\n",
    "        # Read in the data\n",
    "        df = pd.read_csv(file, usecols=cols)\n",
    "        print(\"Data loaded in\")\n",
    "\n",
    "        # Complete the signal, 257 > 258 > 317, then ffill for remaining na\n",
    "        signal = pd.Series(df[cols[1]])\n",
    "        i=2\n",
    "        while True:\n",
    "            try:\n",
    "                signal = signal.combine_first(df[cols[i]])\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                break\n",
    "        signal = signal.fillna(method=\"ffill\")\n",
    "        signal = pd.to_numeric(signal)\n",
    "        print(\"Signals combined and filled in\")\n",
    "\n",
    "        # Remove spikes and troughs by pinpointing values out of bounds and then \n",
    "        # erasing left and right of those pinpoints by delta indices\n",
    "        delta = 125\n",
    "        filt = (signal <= -10) | (signal >= 10)\n",
    "        filt.loc[~filt] = np.nan\n",
    "        filt.fillna(method=\"ffill\", limit=delta, inplace=True)\n",
    "        filt.fillna(method=\"bfill\", limit=delta, inplace=True)\n",
    "        filt.fillna(value=False, inplace=True)\n",
    "\n",
    "        signal.loc[filt] = np.nan\n",
    "        signal.fillna(method=\"ffill\", inplace=True)\n",
    "        print(\"Troughs and spikes removed\")\n",
    "\n",
    "        # Initialize the rpeak list\n",
    "        rpeaks = []\n",
    "\n",
    "        # Create a counter for breaking the signal into chunks\n",
    "        i=0\n",
    "        N = len(signal)\n",
    "        chunk = 10000\n",
    "        num_chunks = N//chunk + 1\n",
    "        print(\"Signal broken into \" + str(num_chunks) + \" chunks\")\n",
    "\n",
    "        # Find R peaks in all but the last chunk (that just tends to cause a problem)\n",
    "        while True:\n",
    "            try:\n",
    "                if i%1000 == 0:\n",
    "                    # I've found this choice of progress marker works for this chunk\n",
    "                    # size and signal length. If those values change, then this \n",
    "                    # condition will need to be modified too\n",
    "                    print( str(round(i/num_chunks,4)*100) + \"% percent done\" )\n",
    "\n",
    "                lo = i*chunk\n",
    "                hi = min( (i+1)*chunk, N)\n",
    "                xqrs = processing.XQRS(sig=signal[lo:hi], fs=freq)\n",
    "                xqrs.detect(verbose=False)\n",
    "\n",
    "                # xqrs recognized the chunk as starting from 0, so we have to shift \n",
    "                # the R peaks according to the left endpoint of the chunk\n",
    "                rpeaks += list( lo + xqrs.qrs_inds )\n",
    "\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                # This is the main way in which we'd expect to break this loop\n",
    "                break\n",
    "            except ValueError:\n",
    "                # More often than not, we get this case because the last chunk isn't \n",
    "                # long enough, hence the next block\n",
    "                break\n",
    "        print(\"R peaks outside of the last chunk located\")\n",
    "\n",
    "        # Delineate an ending chunk of like 20000 indices that gets the end of the\n",
    "        # signal, find R peaks\n",
    "        hi = len(signal)\n",
    "        lo = hi - 20000\n",
    "        xqrs = processing.XQRS(sig=signal[lo:hi], fs=freq)\n",
    "        xqrs.detect(verbose=False)\n",
    "\n",
    "        rpeaks += [ peak for peak in xqrs.qrs_inds if peak > max(rpeaks)]\n",
    "        print(\"Peaks in final chunk located\")\n",
    "\n",
    "        # Grab the time stamps, write them to a file\n",
    "        df.loc[rpeaks, \"time\"].to_csv(\"07-pipeline-outputs/01-rpeaks/rpeaks_\" + namedict[key] + \".csv\", )\n",
    "        print(\"Output file written\")\n",
    "\n",
    "        # Delete all of the variables to save space\n",
    "        del df\n",
    "        del xqrs\n",
    "        del signal\n",
    "        del rpeaks\n",
    "        collect_garbage()\n",
    "\n",
    "        print(str(virtual_memory()[2]) + \" memory usage\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=12655771648, available=5155569664, percent=59.3, used=7500201984, free=5155569664)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now with infant 2\n",
      "Infant 2 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 49.8% memory usage\n",
      "\n",
      "Starting now with infant 3\n",
      "Infant 3 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 49.0% memory usage\n",
      "\n",
      "Starting now with infant 4\n",
      "Infant 4 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 49.3% memory usage\n",
      "\n",
      "Starting now with infant 5\n",
      "Infant 5 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 50.2% memory usage\n",
      "\n",
      "Starting now with infant 6\n",
      "Infant 6 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 49.0% memory usage\n",
      "\n",
      "Starting now with infant 7\n",
      "Infant 7 R-peaks all loaded\n",
      "Unprocessed RR Intervals Written\n",
      "Intervals outside of [0.25, 10] dealt with\n",
      "0.0% Complete\n",
      "100.0% Complete\n",
      "200.0% Complete\n",
      "300.0% Complete\n",
      "400.0% Complete\n",
      "500.0% Complete\n",
      "600.0% Complete\n",
      "700.0% Complete\n",
      "800.0% Complete\n",
      "900.0% Complete\n",
      "1000.0% Complete\n",
      "1100.0% Complete\n",
      "1200.0% Complete\n",
      "1300.0% Complete\n",
      "1400.0% Complete\n",
      "1500.0% Complete\n",
      "1600.0% Complete\n",
      "1700.0% Complete\n",
      "1800.0% Complete\n",
      "1900.0% Complete\n",
      "2000.0% Complete\n",
      "Multiple intervals all broken up\n",
      "Cleaned RR intervals written to file, 54.8% memory usage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ALRIGHT, PART ONE IS DONE, NOW I NEED TO FIX THE RR INTERVALS TO REMOVE DOUBLE INTERVALS, WILL ALSO TAKE A WHILE\n",
    "# Load in the rpeaks for each infant\n",
    "for i in range(2,8):\n",
    "    print(\"Starting now with infant \" + str(i))\n",
    "    # Get the names of the rpeak files\n",
    "    rpeak_files = sorted([\"07-pipeline-outputs/01-rpeaks/rpeaks_\"+str(i)+part+\".csv\" for part in [\"a\", \"b\", \"c\", \"d\", \"e\"]])\n",
    "    \n",
    "    # Concatenate all of these dataframes\n",
    "    df = pd.read_csv( rpeak_files.pop(0) )\n",
    "    for file in rpeak_files:\n",
    "        df = df.append( pd.read_csv( file ) )\n",
    "        collect_garbage()\n",
    "    print(\"Infant \" + str(i) + \" R-peaks all loaded\")\n",
    "    \n",
    "    # Clean up df, calculate the RR intervals, and write the results just in case\n",
    "    df.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df[\"interval\"] = df[\"time\"].diff()\n",
    "    df.to_csv(\"07-pipeline-outputs/02-dirty-rr-intervals/dirty-rr-intervals_\"+str(i)+\".csv\", index=False)\n",
    "    print(\"Unprocessed RR Intervals Written\")\n",
    "\n",
    "    # Recalculate RR intervals while ignoring beats whose RR intervals are > 0.25 seconds\n",
    "    filt = df[\"interval\"] >= 0.25\n",
    "\n",
    "    new_df = pd.DataFrame.copy(df.loc[filt], deep=True)\n",
    "    new_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    new_df[\"interval\"] = new_df[\"time\"].diff()\n",
    "\n",
    "    del df\n",
    "    collect_garbage()\n",
    "    df = pd.DataFrame.copy(new_df, deep=True)\n",
    "    del new_df\n",
    "    collect_garbage()\n",
    "\n",
    "    # Remove intervals of length greater than 5 seconds (this is arbitrary)\n",
    "    # The resulting gaps will just be treated as missing data\n",
    "    filt = df[\"interval\"] <= 5\n",
    "    df = df.loc[filt]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    print(\"Intervals outside of [0.25, 10] dealt with\")\n",
    "\n",
    "    # Get rid of any remaining multiple intervals\n",
    "    df.set_index(df[\"time\"], inplace=True)\n",
    "    df.drop(\"time\", inplace=True, axis=1)\n",
    "\n",
    "    df_buffer = pd.DataFrame.copy(df, deep=True)\n",
    "\n",
    "    # THIS IS THE BULKY PART OF THIS PROCESS, AND IT DOES TAKE A LONG TIME (~1H PER INFANT).\n",
    "    # INVESTIGATION INTO OTHER METHODS WOULD BE WORTHWHILE\n",
    "    # Form a generator to iterate over the rows\n",
    "    rows = df_buffer.iterrows()\n",
    "    progress_chunk = len(df[\"interval\"]) // 20\n",
    "\n",
    "    # Get the initial values\n",
    "    prev_idx, prev_row = next(rows)\n",
    "    prev_ivl = prev_row[\"interval\"]\n",
    "\n",
    "    # A counter to see how many beats were imputed\n",
    "    imputed = 0\n",
    "    max_imputed = 0\n",
    "\n",
    "    # A counter for progress\n",
    "    counter = 0\n",
    "\n",
    "    for curr_idx, curr_row in rows:\n",
    "        if counter % progress_chunk == 0:\n",
    "            print( str(round( counter/progress_chunk, 4)*100) + \"% Complete\" )\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "        curr_ivl = curr_row[\"interval\"]\n",
    "\n",
    "        pieces = round(curr_ivl/prev_ivl)\n",
    "\n",
    "        if pieces >= 2: # then it is likely that the current interval is a multiple interval\n",
    "            fill_value = curr_ivl / pieces\n",
    "\n",
    "            while fill_value < 0.25: # We have too many pieces and the beats are unrealistically small (i.e. < 0.25 seconds)\n",
    "                pieces -= 1\n",
    "                fill_value = curr_ivl/pieces\n",
    "                if pieces == 1:\n",
    "                    break\n",
    "                \n",
    "            if pieces == 1: # Then there's not point in carrying on with this iteration, update previous values and continue\n",
    "                prev_idx = curr_idx\n",
    "                prev_ivl = curr_ivl\n",
    "                continue\n",
    "\n",
    "            imputed += pieces\n",
    "            max_imputed = max(max_imputed, pieces)\n",
    "\n",
    "            # Otherwise, we impute the RR intervals, modifying df and NOT df_buffer\n",
    "            endpoints = [prev_idx + i*fill_value for i in range(1, pieces)] + [curr_idx]\n",
    "            for t in endpoints:\n",
    "                df.loc[t,\"interval\"] = fill_value\n",
    "\n",
    "            # Now, we update the previous values ahead of the next iteration\n",
    "            prev_idx = curr_idx\n",
    "            prev_ivl = fill_value\n",
    "            continue\n",
    "\n",
    "        # If we didn't enter the pieces >= 2 case, then we need to update the previous values in a different way\n",
    "        prev_idx = curr_idx\n",
    "        prev_ivl = curr_ivl\n",
    "\n",
    "    print(\"Multiple intervals all broken up\")\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    df.to_csv(\"07-pipeline-outputs/03-clean-rr-intervals/rr_intervals_imputed_\"+str(i)+\".csv\")\n",
    "    del df\n",
    "    del df_buffer\n",
    "    del rows\n",
    "    collect_garbage()\n",
    "    print(\"Cleaned RR intervals written to file, \"+str(virtual_memory()[2])+\"% memory usage\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138352\n"
     ]
    }
   ],
   "source": [
    "print(imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03989514087957205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "138352/3467891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b66384013171cdfccbfda8d4f96d2b3b6a10bf536bc42f61d1fe50046d47db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
